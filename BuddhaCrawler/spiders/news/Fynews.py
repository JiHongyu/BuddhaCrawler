# -*- coding: utf-8 -*-import scrapyfrom bs4 import BeautifulSoupimport timefrom collections import OrderedDictimport jsonclass FynewItem(scrapy.Item):    title = scrapy.Field()    text = scrapy.Field(serializer=str)    date = scrapy.Field()f = open('articles.txt', 'a+')crawlCount = 0class FynewsSpider(scrapy.Spider):    name = 'fynews'    allowed_domains = ['www.fynews.net']    start_urls = ['https://www.fynews.net/']    def parse(self, response: scrapy.http.Response):        global crawlCount, f        soap = BeautifulSoup(str(response.body, encoding='UTF-8'), 'lxml')        titleTagData = soap.find('h1', class_='ph')        article = soap.select_one('#article_content')        if titleTagData is not None and article is not None:            crawlCount = crawlCount + 1            title = titleTagData.string.strip()            print('%4d\t%s' % (crawlCount, title))            data = OrderedDict()            data['url'] = response.url            data['title'] = title            data['date'] = titleTagData.parent.select_one('p').contents[0].strip()            data['article'] = str(article)            f.write(json.dumps(data, ensure_ascii=False) + '\n')            if crawlCount % 50 == 0:                f.flush()        for aTagData in soap.find_all('a'):            url = aTagData.get('href')            if url is not None and url.find('javascript') < 0 and url.find('http') == 0:                yield scrapy.Request(url=url, callback=self.parse)        time.sleep(0.05)